configfile: "config/config.yaml"

# rule all:
# 	input:
# 		["resources/Data/HMMs/HMMsearch_results/search_lit_sequences_{threshold}.tsv".format(threshold=config["thresholds"][x], 
# 		cluster=big_list_clusters[x][y]) for x in range(len(config["thresholds"])) for y in range(len(big_list_clusters[x]))]
# só para obter a base de dados final de HMM, os resultados do hmmsearch não são precisos
# 		expand("resources/Data/HMMs/After_tcoffee_UPI/{threshold}.hmm", threshold=config["thresholds"])


rule UPIMAPI_search:
	input:
		query="resources/Data/FASTA/DataBases/familiesDB.fasta",
		upi_database="resources/Data/FASTA/literature_seq/lit_sequences.fasta"
		# upi_database=configfile["input_file_db_const"]
	output:
		"resources/Alignments/BLAST/upimapi_results/UPIMAPI_results.tsv"
	params:
		outdir="resources/Alignments/BLAST/upimapi_results"
	threads: config["threads"]
	log:
		"logs/UPIMAPI_search.log"
	conda:
		"envs/upimapi.yaml"
	shell:
		"upimapi.py -i {input.query} -o {params.outdir} --database {input.upi_database} -t {threads}"


rule UPIMAPI_parse:
	input:
		"resources/Alignments/BLAST/upimapi_results/UPIMAPI_results.tsv"
	output:
		"resources/Data/Tables/UPIMAPI_results_per_sim.tsv"
	threads: config["threads"]
	log:
		"logs/UPIMAPI_parse.log"
	conda:
		"envs/pandas.yaml"
	script:
		"scripts/db_construction/UPIMAPI_parser.py"


wildcard_constraints:
    threshold="[0-9 \-]+",
	cluster="[0-9]+"


rule seq_download:
# esta fica dependente da proxima regra, ou seja, so corre quando se pede a initial_cdhit_per_threshold
	input:
		"resources/Data/Tables/UPIMAPI_results_per_sim.tsv"
	output:
		"resources/Data/FASTA/UPIMAPI/{threshold}.fasta"  # terá que fazer os ficheiros para todos os thresholds de uma só vez
	threads: config["threads"]
	log:
		"logs/seq_download_{threshold}.log"
	script:
		"scripts/db_construction/seq_download.py"


# rule mockup:
# 	input:
# 		expand("resources/Data/FASTA/UPIMAPI/{threshold}.fasta", threshold=config["thresholds"])
# 	output:
# 		"mockup.out"
# 	run:
# 		with open("mockup.out", "w") as f:
# 			f.write("sucess!")


rule initial_cdhit_per_threshold:
	input:
		"resources/Data/FASTA/UPIMAPI/{threshold}.fasta"  # é o output da regra anterior com wildcards
	output:
		"resources/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta",  # after upimapi!
	threads: config["threads"]
	log:
		"logs/initial_cdhit_per_threshold_{threshold}.log"
	shell:
		"cd-hit -i {input} -o {output} -c 0.9 -n 5 -M 16000 -d 0 -T 8"


# rule mockup:
# 	input:
# 		expand("resources/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta", threshold=config["thresholds"])
# 	output:
# 		"mockup.out"
# 	run:
# 		with open("mockup.out", "w") as f:
# 			f.write("sucess!")


rule cdhit_parse:
	input:
		"resources/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta.clstr"
	output:
		"resources/Data/Tables/CDHIT_clusters/cdhit_clusters_{threshold}_afterUPIMAPI.tsv"
	threads: config["threads"]
	log:
		"logs/cdhit_parse_{threshold}.log"
	script:
		"scripts/db_construction/CDHIT_parser.py"


# rule mockup:
# 	input:
# 		expand("resources/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv", threshold=config["thresholds"])
# 	output:
# 		"mockup.out"
# 	run:
# 		with open("mockup.out", "w") as f:
# 			f.write("sucess!")


from scripts.snakemake_util import get_clusters
from glob import glob
# vai buscar aos .tsv criados antes, e não fica dependente dos fasta que vão ser criados
files = {threshold: glob(f"resources/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv") for threshold in config["thresholds"]}
threshold2clusters = {}
for thresh, path in files.items():
	threshold2clusters[thresh] = get_clusters(path[0])

# fazer uma lista de listas com todos os clusters, por ordem de threshold
big_list_clusters = [v for k, v in threshold2clusters.items()]


rule seq_download_cdhit:
	input:
		"resources/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv"
	output:
		# um ficheiro por cada cluster, por threshold, com as sequencias
		"resources/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta"
		# expand("resources/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta", filtered_product, threshold=config["thresholds"], cluster=all_clusters)
	threads: config["threads"]
	log:
		"logs/seq_download_cdhit{threshold}_{cluster}.log"
	script:
		"scripts/db_construction/CDHIT_seq_download.py" # from_cdhit


# rule mockup:
# 	input:
# 		# expand("resources/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta", threshold=config["thresholds"], 
# 		# cluster=(threshold2clusters[threshold][clt] for threshold in config["thresholds"] for clt in range(len(threshold2clusters[threshold]))))
# 		["resources/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta".format(threshold=config["thresholds"][x], 
# 		cluster=big_list_clusters[x][y]) for x in range(len(config["thresholds"])) for y in range(len(big_list_clusters[x]))]
# 	output:
# 		"mockup.out"
# 	run:
# 		with open("mockup.out", "w") as f:
# 			f.write("sucess!")


rule t_coffee:
	input:
		# ["resources/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta".format(threshold=config["thresholds"][x], 
		# cluster=big_list_clusters[x][y]) for x in range(len(config["thresholds"])) for y in range(len(big_list_clusters[x]))]
		"resources/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta"
	output:
		"resources/Alignments/MultipleSequencesAlign/T_Coffee_UPI/{threshold}/{cluster}.clustal_aln"
		# expand("resources/Alignments/MultipleSequencesAlign/T_Coffee_UPI/{threshold}/{cluster}.clustal_aln", threshold=config["thresholds"], cluster=threshold2clusters[threshold])
	threads: config["threads"]
	log:
		"logs/t_coffee_{threshold}_{cluster}.log"
	# script:
	# 	"scripts/db_construction/t_coffee_run.py"
	shell:
		"t_coffee {input} -output clustalw_aln -outfile {output}"


# rule mockup:
#  	input:
#  		["resources/Alignments/MultipleSequencesAlign/T_Coffee_UPI/{threshold}/{cluster}.clustal_aln".format(threshold=config["thresholds"][x], 
# 		cluster=big_list_clusters[x][y]) for x in range(len(config["thresholds"])) for y in range(len(big_list_clusters[x]))]
#  	output:
#  		"mockup.out"
#  	run:
#  		with open("mockup.out", "w") as f:
#  			f.write("sucess!")


rule hmmbuild:
	input:
		"resources/Alignments/MultipleSequencesAlign/T_Coffee_UPI/{threshold}/{cluster}.clustal_aln"
	output:
		"resources/Data/HMMs/After_tcoffee_UPI/{threshold}/{cluster}.hmm"
	threads: config["threads"]
	log:
		"logs/hmmbuild_{threshold}_{cluster}.log"
	shell:
		"hmmbuild {output} {input}"


# rule mockup:
#  	input:
#  		["resources/Data/HMMs/After_tcoffee_UPI/{threshold}/{cluster}.hmm".format(threshold=config["thresholds"][x], 
# 		cluster=big_list_clusters[x][y]) for x in range(len(config["thresholds"])) for y in range(len(big_list_clusters[x]))]
#  	output:
#  		"mockup.out"
#  	run:
#  		with open("mockup.out", "w") as f:
#  			f.write("sucess!")


files = {threshold: glob(f"resources/Data/FASTA/CDHIT/{threshold}/*.fasta") for threshold in config["thresholds"]}
threshold2clusters = {k : [v.split("/")[-1].split("\\")[-1].split('.f')[0] for v in values] for k, values in files.items()}

# from scripts.snakemake_util import cat_hmms_input

def cat_hmms_input(wildcards):
	return expand("resources/Data/HMMs/After_tcoffee_UPI/{threshold}/{cluster}.hmm", threshold=wildcards, cluster=threshold2clusters[wildcards])


rule cat_hmms:
	input:
	    lambda wildcards: cat_hmms_input(wildcards.threshold)
	output:
		"resources/Data/HMMs/After_tcoffee_UPI/{threshold}.hmm"
	threads: config["threads"]
	log:
		"logs/cat_hmms_{threshold}.log"
	shell:
		"cat {input} > {output}"


rule mockup:
	input:
		expand("resources/Data/HMMs/After_tcoffee_UPI/{threshold}.hmm", threshold=config["thresholds"])
	output:
		"mockup.out"
	run:
 		with open("mockup.out", "w") as f:
 			f.write("sucess!")


# rule hmmsearch:
# 	input:
# 		hmms = "resources/Data/HMMs/After_tcoffee_UPI/{threshold}.hmm",
# 		database = "resources/Data/FASTA/Databases/familiesDB.fasta"
# 	output:
# 		"resources/Data/HMMs/HMMsearch_results/search_lit_sequences_{threshold}.tsv"
#	threads: config["threads"]
#	log:
#		"logs/hmmsearch.log"
# 	shell:
# 		"hmmsearch --tblout {output} {input.hmms} {input.database}"